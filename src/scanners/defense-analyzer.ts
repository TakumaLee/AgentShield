import { ScannerModule, ScanResult, Finding, Severity } from '../types';
import { findPromptFiles, readFileContent, isTestOrDocFile, findFiles } from '../utils/file-utils';

interface DefenseCategory {
  id: string;
  name: string;
  patterns: { pattern: RegExp; weight: number; desc: string }[];
  missingSeverity: Severity;
  partialSeverity: Severity;
  recommendation: string;
  /** Minimum total weight to consider defense "present" */
  threshold: number;
  /** Minimum total weight for "partial" (below threshold) */
  partialThreshold: number;
}

const DEFENSE_CATEGORIES: DefenseCategory[] = [
  {
    id: 'DF-001',
    name: 'Input Sanitization',
    patterns: [
      { pattern: /sanitiz[ei]/i, weight: 3, desc: 'sanitize function' },
      { pattern: /(?:validate|validation)\s*\(/i, weight: 3, desc: 'input validation' },
      { pattern: /(?:strip|escape|encode)(?:Html|Xml|Sql|Input|Tags)/i, weight: 3, desc: 'strip/escape function' },
      { pattern: /(?:filter|clean)(?:Input|User|Query|Data)/i, weight: 2, desc: 'filter/clean function' },
      { pattern: /new\s+RegExp|\/\^[^/]+\$\//i, weight: 1, desc: 'regex validation' },
      { pattern: /z\.(?:string|number|object|array)\(\)/i, weight: 2, desc: 'zod schema validation' },
      { pattern: /(?:joi|yup|ajv|zod)\.(validate|parse|check)/i, weight: 3, desc: 'schema validation library' },
      { pattern: /xss[_-]?(?:clean|filter|protect|guard)/i, weight: 3, desc: 'XSS protection' },
      { pattern: /(?:whitelist|allowlist|denylist|blocklist)\s*[=:]/i, weight: 2, desc: 'allowlist/denylist' },
      { pattern: /input[_.]?(?:check|guard|verify)/i, weight: 2, desc: 'input guard' },
      // Prompt/markdown patterns — natural language security rules
      { pattern: /視為純文字.*不執行|不執行.*視為純文字/i, weight: 3, desc: 'treat external input as plain text (prompt)' },
      { pattern: /外部.*(?:內容|輸入).*(?:忽略|拒絕|不信任)/i, weight: 2, desc: 'reject external input (prompt)' },
      { pattern: /treat\s+(?:as\s+)?plain\s+text|do\s+not\s+execute/i, weight: 2, desc: 'treat as plain text directive' },
    ],
    missingSeverity: 'high',
    partialSeverity: 'medium',
    recommendation: 'Add input sanitization: validate and sanitize all user input before processing. Use schema validation libraries (zod, joi) and escape/strip dangerous content.',
    threshold: 4,
    partialThreshold: 1,
  },
  {
    id: 'DF-002',
    name: 'System Prompt Hardening',
    patterns: [
      { pattern: /you\s+MUST/i, weight: 2, desc: 'instruction emphasis (MUST)' },
      { pattern: /NEVER\s+(?:override|ignore|bypass|reveal|share|disclose)/i, weight: 3, desc: 'NEVER directive' },
      { pattern: /ignore\s+(?:any\s+)?user\s+attempts?\s+to/i, weight: 3, desc: 'anti-override instruction' },
      { pattern: /do\s+not\s+(?:reveal|share|disclose|output)\s+(?:your\s+)?(?:system|initial)\s+(?:prompt|instructions)/i, weight: 3, desc: 'prompt leak prevention instruction' },
      { pattern: /\[SYSTEM\]|\[system\]|role:\s*system/i, weight: 2, desc: 'system/user role separation' },
      { pattern: /instruction\s+hierarchy|system\s*>\s*user|priority:\s*system/i, weight: 3, desc: 'instruction hierarchy' },
      { pattern: /role[_-]?lock|identity[_-]?lock|persona[_-]?lock/i, weight: 3, desc: 'role-lock pattern' },
      { pattern: /you\s+are\s+(?:only|strictly|exclusively)\s+a/i, weight: 2, desc: 'strict role definition' },
      { pattern: /under\s+no\s+circumstances/i, weight: 2, desc: 'absolute restriction' },
      { pattern: /regardless\s+of\s+(?:what|any)\s+(?:the\s+)?user/i, weight: 2, desc: 'user-override prevention' },
      // Prompt/markdown patterns
      { pattern: /身份不可.*(?:改變|侵犯|覆寫)/i, weight: 3, desc: 'identity lock (Chinese prompt)' },
      { pattern: /指令優先級|指令.*優先/i, weight: 3, desc: 'instruction hierarchy (Chinese prompt)' },
      { pattern: /(?:全部|一律).*忽略/i, weight: 2, desc: 'blanket ignore directive (Chinese prompt)' },
      { pattern: /不可被.*外部.*改變/i, weight: 3, desc: 'immutable identity (Chinese prompt)' },
      { pattern: /假裝.*→.*(?:不信任|忽略)/i, weight: 2, desc: 'anti-impersonation (Chinese prompt)' },
      { pattern: /instruction\s+priority|priority.*order/i, weight: 2, desc: 'instruction priority (English prompt)' },
    ],
    missingSeverity: 'high',
    partialSeverity: 'medium',
    recommendation: 'Harden system prompts: add instruction hierarchy (system > user), role-lock patterns, and explicit directives to never override system instructions or reveal the prompt.',
    threshold: 5,
    partialThreshold: 2,
  },
  {
    id: 'DF-003',
    name: 'Output Filtering',
    patterns: [
      { pattern: /output[_.]?(?:filter|guard|check|sanitize|validate)/i, weight: 3, desc: 'output filter' },
      { pattern: /response[_.]?(?:filter|guard|check|sanitize|validate)/i, weight: 3, desc: 'response filter' },
      { pattern: /(?:check|verify|detect)\s+(?:if\s+)?(?:output|response)\s+contains/i, weight: 2, desc: 'output content check' },
      { pattern: /prompt[_.]?leak[_.]?(?:detect|prevent|check|guard)/i, weight: 3, desc: 'prompt leak prevention' },
      { pattern: /(?:redact|mask|censor)\s+(?:sensitive|secret|private|pii)/i, weight: 3, desc: 'sensitive data redaction' },
      { pattern: /output[_.]?(?:allow|deny|block)list/i, weight: 2, desc: 'output allowlist/denylist' },
      { pattern: /post[_-]?process(?:ing)?\s+(?:response|output)/i, weight: 2, desc: 'response post-processing' },
      { pattern: /guardrail/i, weight: 2, desc: 'guardrail pattern' },
      // Prompt/markdown patterns
      { pattern: /回覆前.*(?:檢查|確認).*(?:包含|含有)/i, weight: 3, desc: 'pre-reply check (Chinese prompt)' },
      { pattern: /不透露.*(?:私人|敏感|設定)/i, weight: 2, desc: 'no disclosure rule (Chinese prompt)' },
      { pattern: /輸出.*(?:system prompt|SOUL|設定).*(?:拒絕|不)/i, weight: 3, desc: 'refuse prompt output (Chinese prompt)' },
      { pattern: /(?:before|prior\s+to)\s+(?:replying|responding).*(?:check|verify|ensure)/i, weight: 2, desc: 'pre-reply check (English prompt)' },
      { pattern: /要求.*輸出.*(?:拒絕|不)/i, weight: 2, desc: 'refuse output request (Chinese prompt)' },
    ],
    missingSeverity: 'high',
    partialSeverity: 'medium',
    recommendation: 'Add output filtering: implement response guards to detect prompt leaks, redact sensitive data, and validate output before returning to users.',
    threshold: 4,
    partialThreshold: 1,
  },
  {
    id: 'DF-004',
    name: 'Sandbox/Permission Boundaries',
    patterns: [
      { pattern: /sandbox(?:ed|ing)?/i, weight: 3, desc: 'sandbox configuration' },
      { pattern: /(?:permission|access)[_.]?(?:config|settings|policy|control)/i, weight: 3, desc: 'permission configuration' },
      { pattern: /(?:allow|deny|block)list/i, weight: 2, desc: 'allowlist/denylist' },
      { pattern: /(?:allowed|blocked|denied)[_.]?(?:paths|commands|tools|domains)/i, weight: 3, desc: 'scoped access control' },
      { pattern: /least[_-]?privilege/i, weight: 2, desc: 'least-privilege principle' },
      { pattern: /(?:chroot|jail|container|isolation)/i, weight: 2, desc: 'isolation mechanism' },
      { pattern: /(?:read[_-]?only|no[_-]?write|immutable)/i, weight: 1, desc: 'read-only restriction' },
      { pattern: /security[_.]?(?:boundary|perimeter|scope)/i, weight: 2, desc: 'security boundary' },
      // Prompt/markdown patterns
      { pattern: /allowFrom|groupPolicy/i, weight: 3, desc: 'access control config' },
      { pattern: /只(?:允許|接受).*(?:主人|owner|admin)/i, weight: 3, desc: 'owner-only access (Chinese prompt)' },
      { pattern: /明確拒絕事項|一律拒絕/i, weight: 2, desc: 'explicit rejection list (Chinese prompt)' },
    ],
    missingSeverity: 'high',
    partialSeverity: 'medium',
    recommendation: 'Define sandbox/permission boundaries: configure allowlists for paths, commands, and domains. Apply the principle of least privilege.',
    threshold: 4,
    partialThreshold: 1,
  },
  {
    id: 'DF-005',
    name: 'Authentication/Pairing Mechanisms',
    patterns: [
      { pattern: /(?:auth|authenticate|authentication)\s*[(:=]/i, weight: 3, desc: 'authentication check' },
      { pattern: /(?:verify|validate)[_.]?(?:identity|token|session|user)/i, weight: 3, desc: 'identity verification' },
      { pattern: /pairing[_.]?(?:flow|code|token|secret)/i, weight: 3, desc: 'pairing mechanism' },
      { pattern: /(?:api[_-]?key|bearer|jwt|oauth)/i, weight: 2, desc: 'auth token type' },
      { pattern: /(?:session|cookie)[_.]?(?:check|verify|validate)/i, weight: 2, desc: 'session validation' },
      { pattern: /(?:require|ensure)[_.]?auth/i, weight: 3, desc: 'auth requirement' },
      { pattern: /(?:isAuthenticated|isAuthorized|checkPermission)/i, weight: 3, desc: 'auth guard function' },
      { pattern: /(?:unauthorized|forbidden|401|403)\b/i, weight: 1, desc: 'auth error handling' },
      // Prompt/markdown patterns
      { pattern: /只有.*(?:Telegram|id:\s*\d+).*是.*(?:主人|owner)/i, weight: 3, desc: 'identity-bound auth (Chinese prompt)' },
      { pattern: /只接受.*(?:系統|主人).*指令/i, weight: 2, desc: 'accept only system/owner commands (Chinese prompt)' },
    ],
    missingSeverity: 'high',
    partialSeverity: 'medium',
    recommendation: 'Implement authentication and pairing mechanisms: require identity verification before granting access to agent capabilities.',
    threshold: 4,
    partialThreshold: 1,
  },
  {
    id: 'DF-006',
    name: 'Canary Tokens/Tripwires',
    patterns: [
      { pattern: /canary[_.]?(?:token|string|value|check)/i, weight: 3, desc: 'canary token' },
      { pattern: /honeypot/i, weight: 3, desc: 'honeypot pattern' },
      { pattern: /tripwire/i, weight: 3, desc: 'tripwire mechanism' },
      { pattern: /integrity[_.]?(?:check|verify|hash|validation)/i, weight: 2, desc: 'integrity verification' },
      { pattern: /tamper[_.]?(?:detect|check|proof|evident)/i, weight: 3, desc: 'tamper detection' },
      { pattern: /watermark/i, weight: 2, desc: 'watermark pattern' },
      { pattern: /(?:checksum|hash[_.]?verify)/i, weight: 1, desc: 'checksum verification' },
      { pattern: /(?:fingerprint|signature)[_.]?(?:check|verify)/i, weight: 2, desc: 'signature verification' },
    ],
    missingSeverity: 'high',
    partialSeverity: 'medium',
    recommendation: 'Add canary tokens or tripwires: embed detectable markers that trigger alerts if system prompts or configurations are leaked or tampered with.',
    threshold: 3,
    partialThreshold: 1,
  },
];

// === DF-007: Prompt Leak Protection ===

/** Patterns that indicate sensitive data embedded in prompts/system files */
const SENSITIVE_DATA_PATTERNS: { pattern: RegExp; desc: string }[] = [
  { pattern: /(?:api[_-]?key|apikey)\s*[:=]\s*["']?[A-Za-z0-9_\-]{16,}/i, desc: 'API key' },
  { pattern: /(?:secret|password|passwd|pwd)\s*[:=]\s*["']?[^\s"']{8,}/i, desc: 'secret/password' },
  { pattern: /https?:\/\/[^\s"']*[?&](?:token|key|secret|api_key)=[^\s"'&]+/i, desc: 'URL with embedded token' },
  { pattern: /(?:mongodb|postgres|mysql|redis|amqp):\/\/[^\s"']+/i, desc: 'database connection string' },
  { pattern: /(?:internal|private)[_-]?(?:endpoint|api|url|host)\s*[:=]\s*["']?https?:\/\//i, desc: 'internal endpoint' },
  { pattern: /Bearer\s+[A-Za-z0-9_\-\.]{20,}/i, desc: 'Bearer token' },
  { pattern: /-----BEGIN\s+(?:RSA\s+)?PRIVATE\s+KEY-----/i, desc: 'private key' },
  { pattern: /sk-[A-Za-z0-9]{20,}/i, desc: 'OpenAI-style API key' },
  { pattern: /ghp_[A-Za-z0-9]{36,}/i, desc: 'GitHub personal access token' },
  { pattern: /xox[bpsar]-[A-Za-z0-9\-]+/i, desc: 'Slack token' },
];

/** Patterns that indicate prompt-level leak protection (weak defense layer) */
const PROMPT_LEVEL_PROTECTION_PATTERNS: { pattern: RegExp; weight: number; desc: string }[] = [
  { pattern: /never\s+reveal\s+(?:your\s+)?(?:system\s+)?(?:prompt|instructions)/i, weight: 2, desc: 'never reveal instructions' },
  { pattern: /do\s+not\s+share\s+(?:your\s+)?(?:system\s+)?(?:prompt|instructions)/i, weight: 2, desc: 'do not share instructions' },
  { pattern: /refuse\s+to\s+(?:output|reveal|share|disclose)\s+(?:your\s+)?(?:system\s+)?prompt/i, weight: 2, desc: 'refuse to output system prompt' },
  { pattern: /(?:keep|maintain)\s+(?:your\s+)?(?:system\s+)?(?:prompt|instructions)\s+(?:secret|private|confidential)/i, weight: 2, desc: 'keep prompt secret' },
  { pattern: /(?:do\s+not|never|don'?t)\s+(?:output|print|display|echo|repeat)\s+(?:your\s+)?(?:system|initial)\s+(?:prompt|instructions|message)/i, weight: 2, desc: 'do not output system prompt' },
  { pattern: /if\s+(?:asked|someone\s+asks)\s+(?:for|about)\s+(?:your\s+)?(?:system\s+)?(?:prompt|instructions).*(?:refuse|decline|ignore|deny)/i, weight: 2, desc: 'refuse prompt extraction attempts' },
];

/** Patterns indicating server-side architecture (positive for prompt leak defense) */
const SERVER_SIDE_PATTERNS: { pattern: RegExp; weight: number; desc: string }[] = [
  { pattern: /(?:app|router)\.(get|post|put|delete|patch)\s*\(/i, weight: 2, desc: 'API route handler' },
  { pattern: /(?:express|fastify|koa|hono|next)\s*[\.(]/i, weight: 1, desc: 'server framework' },
  { pattern: /(?:req|request)\s*\.\s*(?:body|params|query)/i, weight: 1, desc: 'request parsing' },
  { pattern: /(?:res|response)\s*\.\s*(?:json|send|status)/i, weight: 1, desc: 'response handling' },
  { pattern: /middleware/i, weight: 1, desc: 'middleware pattern' },
];

export interface PromptLeakAnalysis {
  sensitiveDataFound: { desc: string; file: string }[];
  hasOutputFiltering: boolean;
  promptProtectionWeight: number;
  promptProtectionPatterns: string[];
  serverSideWeight: number;
  serverSidePatterns: string[];
}

export function analyzeSensitiveDataInPrompt(content: string, filePath: string): { desc: string; file: string }[] {
  const found: { desc: string; file: string }[] = [];
  for (const p of SENSITIVE_DATA_PATTERNS) {
    if (p.pattern.test(content)) {
      found.push({ desc: p.desc, file: filePath });
    }
  }
  return found;
}

export function analyzePromptLevelProtection(content: string): { weight: number; patterns: string[] } {
  let weight = 0;
  const patterns: string[] = [];
  for (const p of PROMPT_LEVEL_PROTECTION_PATTERNS) {
    if (p.pattern.test(content)) {
      weight += p.weight;
      patterns.push(p.desc);
    }
  }
  return { weight, patterns };
}

export function analyzeServerSideArchitecture(content: string): { weight: number; patterns: string[] } {
  let weight = 0;
  const patterns: string[] = [];
  for (const p of SERVER_SIDE_PATTERNS) {
    if (p.pattern.test(content)) {
      weight += p.weight;
      patterns.push(p.desc);
    }
  }
  return { weight, patterns };
}

export function generatePromptLeakFindings(analysis: PromptLeakAnalysis, targetPath: string): Finding[] {
  const findings: Finding[] = [];
  const hasSensitiveData = analysis.sensitiveDataFound.length > 0;
  const hasOutputFiltering = analysis.hasOutputFiltering;
  const hasPromptProtection = analysis.promptProtectionWeight > 0;
  const hasServerSide = analysis.serverSideWeight >= 3;

  // If sensitive data found in prompts, always report it
  if (hasSensitiveData) {
    const dataTypes = [...new Set(analysis.sensitiveDataFound.map(d => d.desc))].join(', ');
    const severity: Severity = hasOutputFiltering ? 'high' : 'critical';
    findings.push({
      id: 'DF-007-SENSITIVE',
      scanner: 'defense-analyzer',
      severity,
      title: 'System prompt contains sensitive data',
      description: `System prompt or configuration contains sensitive data (${dataTypes}) that would be exposed if the prompt is leaked.${hasOutputFiltering ? ' Output filtering exists but may not fully prevent extraction.' : ' No output filtering detected to prevent extraction.'}`,
      file: targetPath,
      recommendation: 'Remove sensitive data (API keys, tokens, connection strings) from prompts. Store them server-side in environment variables or secret managers, never in prompt text.',
    });
  }

  // Assess overall prompt leak protection posture
  if (hasSensitiveData && !hasOutputFiltering) {
    // Already covered by SENSITIVE finding above as critical
  } else if (!hasSensitiveData && !hasOutputFiltering) {
    findings.push({
      id: 'DF-007-NOFILTER',
      scanner: 'defense-analyzer',
      severity: 'high',
      title: 'No prompt leak protection',
      description: 'No output filtering or prompt leak prevention mechanisms detected. System prompts could be extracted through prompt injection.',
      file: targetPath,
      recommendation: 'Add output filtering to detect and block prompt leak attempts. Implement response guards that check if output contains system prompt content.',
    });
  } else if (!hasSensitiveData && hasOutputFiltering && !hasPromptProtection && !hasServerSide) {
    findings.push({
      id: 'DF-007-PARTIAL',
      scanner: 'defense-analyzer',
      severity: 'medium',
      title: 'Partial prompt leak protection',
      description: 'Output filtering exists but no additional prompt-level or architecture-level protection layers detected. Defense-in-depth is recommended.',
      file: targetPath,
      recommendation: 'Add prompt-level instructions to refuse system prompt disclosure. Move sensitive logic server-side where possible. Use canary tokens to detect leaks.',
    });
  }

  // Note weak prompt-level protection if that's the only layer
  if (hasPromptProtection && !hasOutputFiltering) {
    findings.push({
      id: 'DF-007-WEAKONLY',
      scanner: 'defense-analyzer',
      severity: 'medium',
      title: 'Prompt leak protection relies on weak layer only',
      description: `Prompt-level protection found (${analysis.promptProtectionPatterns.join(', ')}) but this is a weak defense layer that can be bypassed through prompt injection. No output filtering detected.`,
      file: targetPath,
      recommendation: 'Prompt-level instructions alone are insufficient. Add output filtering/guardrails that programmatically detect and block prompt leak attempts.',
    });
  }

  return findings;
}

export function analyzeDefenses(content: string, filePath: string): { category: string; id: string; totalWeight: number; matchedPatterns: string[] }[] {
  const results: { category: string; id: string; totalWeight: number; matchedPatterns: string[] }[] = [];

  for (const cat of DEFENSE_CATEGORIES) {
    let totalWeight = 0;
    const matchedPatterns: string[] = [];

    for (const p of cat.patterns) {
      if (p.pattern.test(content)) {
        totalWeight += p.weight;
        matchedPatterns.push(p.desc);
      }
    }

    results.push({
      category: cat.name,
      id: cat.id,
      totalWeight,
      matchedPatterns,
    });
  }

  return results;
}

export function generateDefenseFindings(
  categoryResults: Map<string, { totalWeight: number; matchedPatterns: string[]; files: string[] }>,
  targetPath: string,
): Finding[] {
  const findings: Finding[] = [];

  for (const cat of DEFENSE_CATEGORIES) {
    const result = categoryResults.get(cat.id);
    const totalWeight = result?.totalWeight ?? 0;
    const matchedPatterns = result?.matchedPatterns ?? [];

    if (totalWeight < cat.partialThreshold) {
      // MISSING defense
      findings.push({
        id: `${cat.id}-MISSING`,
        scanner: 'defense-analyzer',
        severity: cat.missingSeverity,
        title: `Missing defense: ${cat.name}`,
        description: `No evidence of ${cat.name.toLowerCase()} found in the codebase. This is a critical gap in your security posture.`,
        file: targetPath,
        recommendation: cat.recommendation,
      });
    } else if (totalWeight < cat.threshold) {
      // PARTIAL defense
      findings.push({
        id: `${cat.id}-PARTIAL`,
        scanner: 'defense-analyzer',
        severity: cat.partialSeverity,
        title: `Partial defense: ${cat.name}`,
        description: `Some ${cat.name.toLowerCase()} patterns found (${matchedPatterns.join(', ')}), but coverage appears incomplete. Consider strengthening this defense.`,
        file: targetPath,
        recommendation: cat.recommendation,
      });
    }
    // else: defense is adequate, no finding
  }

  return findings;
}

export const defenseAnalyzer: ScannerModule = {
  name: 'Defense Analyzer',
  description: 'Checks if a codebase has proper injection defenses including input sanitization, prompt hardening, output filtering, sandboxing, auth, and canary tokens',

  async scan(targetPath: string, options?: { exclude?: string[] }): Promise<ScanResult> {
    const start = Date.now();
    const findings: Finding[] = [];
    const files = await findPromptFiles(targetPath, options?.exclude);

    // Aggregate defense signals across all files
    const categoryResults = new Map<string, { totalWeight: number; matchedPatterns: string[]; files: string[] }>();

    for (const cat of DEFENSE_CATEGORIES) {
      categoryResults.set(cat.id, { totalWeight: 0, matchedPatterns: [], files: [] });
    }

    for (const file of files) {
      try {
        const content = readFileContent(file);
        const fileResults = analyzeDefenses(content, file);

        for (const fr of fileResults) {
          const existing = categoryResults.get(fr.id)!;
          if (fr.totalWeight > 0) {
            existing.totalWeight += fr.totalWeight;
            existing.matchedPatterns.push(...fr.matchedPatterns);
            existing.files.push(file);
          }
        }
      } catch {
        // Skip unreadable files
      }
    }

    // Deduplicate matched patterns
    for (const [, result] of categoryResults) {
      result.matchedPatterns = [...new Set(result.matchedPatterns)];
    }

    // Generate findings based on aggregated results
    const defenseFindings = generateDefenseFindings(categoryResults, targetPath);

    // === DF-007: Prompt Leak Protection (cross-cutting analysis) ===
    const promptLeakAnalysis: PromptLeakAnalysis = {
      sensitiveDataFound: [],
      hasOutputFiltering: false,
      promptProtectionWeight: 0,
      promptProtectionPatterns: [],
      serverSideWeight: 0,
      serverSidePatterns: [],
    };

    // Check output filtering from DF-003 results
    const df003 = categoryResults.get('DF-003');
    if (df003 && df003.totalWeight >= 4) {
      promptLeakAnalysis.hasOutputFiltering = true;
    }

    // Scan all files for sensitive data, prompt protection, and server-side patterns
    // Also include source files for architecture analysis
    let sourceFiles: string[] = [];
    try {
      sourceFiles = await findFiles(targetPath, ['**/*.ts', '**/*.js', '**/*.py'], options?.exclude);
    } catch {
      // Ignore errors finding source files
    }
    const allAnalysisFiles = [...new Set([...files, ...sourceFiles])];

    for (const file of allAnalysisFiles) {
      try {
        const content = readFileContent(file);

        // Check for sensitive data in prompt-like files
        const sensitiveHits = analyzeSensitiveDataInPrompt(content, file);
        promptLeakAnalysis.sensitiveDataFound.push(...sensitiveHits);

        // Check for prompt-level protection
        const promptProt = analyzePromptLevelProtection(content);
        promptLeakAnalysis.promptProtectionWeight += promptProt.weight;
        promptLeakAnalysis.promptProtectionPatterns.push(...promptProt.patterns);

        // Check for server-side architecture
        const serverSide = analyzeServerSideArchitecture(content);
        promptLeakAnalysis.serverSideWeight += serverSide.weight;
        promptLeakAnalysis.serverSidePatterns.push(...serverSide.patterns);
      } catch {
        // Skip unreadable files
      }
    }

    // Deduplicate
    promptLeakAnalysis.promptProtectionPatterns = [...new Set(promptLeakAnalysis.promptProtectionPatterns)];
    promptLeakAnalysis.serverSidePatterns = [...new Set(promptLeakAnalysis.serverSidePatterns)];

    const promptLeakFindings = generatePromptLeakFindings(promptLeakAnalysis, targetPath);
    defenseFindings.push(...promptLeakFindings);

    // Downgrade test/doc findings
    for (const f of defenseFindings) {
      if (f.file && isTestOrDocFile(f.file)) {
        if (f.severity === 'critical') f.severity = 'medium';
        else if (f.severity === 'high') f.severity = 'info';
        f.description += ' [test/doc file — severity reduced]';
      }
    }

    findings.push(...defenseFindings);

    return {
      scanner: 'Defense Analyzer',
      findings,
      scannedFiles: files.length,
      duration: Date.now() - start,
    };
  },
};
